# Deep-Learning-Resources

This is basically a collection all resources which I found to be useful for studying the theory of Deep Learning.

[1] Course from deeplearning.ai : https://www.youtube.com/channel/UCcIXc5mJsHVYTZR1maL5l9w/playlists

The explanations for CNNs are quite good. In addition they have a section for sequential modeling coming soon!
Note the sequence models lectures are already uploaded here !!
https://www.youtube.com/playlist?list=PLkDaE6sCZn6F6wUI9tvS_Gw1vaFAx6rd6

[2] RNN's : The lectures by Prof Ali Ghodsi at https://www.youtube.com/watch?v=AvyhbrQptHk&t=4047s and https://www.youtube.com/watch?v=EAt9_4IhC7s&t=8s are excellant. 

[3] In addition to learn more about LSTM and GRU's please look through the blog post here http://colah.github.io/posts/2015-08-Understanding-LSTMs/

[4] To understand word-2-vec model with complete derivations (a) https://www.youtube.com/watch?v=TsEGsdVJjuA&list=PLehuLRPyt1Hyi78UOkMPWCGRxGcA9NVOE&index=5 (b) https://www.youtube.com/watch?v=nuirUEmbaJU&list=PLehuLRPyt1Hyi78UOkMPWCGRxGcA9NVOE&index=6. 

Derivation for the negative sampling is also provided here : https://arxiv.org/pdf/1402.3722.pdf

Alternate Resources : (a) http://mccormickml.com/assets/word2vec/Alex_Minnaar_Word2Vec_Tutorial_Part_I_The_Skip-Gram_Model.pdf and 
(b) http://mccormickml.com/assets/word2vec/Alex_Minnaar_Word2Vec_Tutorial_Part_II_The_Continuous_Bag-of-Words_Model.pdf

To understand without derivations http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/

[5] To understand the basic working of GAN's I would recommend reading up on the main papers.
Mainly I read the blogs in https://github.com/wiseodd/generative-models
