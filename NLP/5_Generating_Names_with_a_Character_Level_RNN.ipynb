{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Names with a Character-Level RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read it here https://pytorch.org/tutorials/intermediate/char_rnn_generation_tutorial.html\n",
    "\n",
    "In the last tutorial we used a RNN to classify names into their language \n",
    "of origin. This time we will turn around and generate names from \n",
    "languages.\n",
    "\n",
    "> python sample.py Russian RUS\n",
    "Rovakov\n",
    "Uantov\n",
    "Shavakov\n",
    "\n",
    "> python sample.py German GER\n",
    "Gerren\n",
    "Ereng\n",
    "Rosher\n",
    "\n",
    "> python sample.py Spanish SPA\n",
    "Salla\n",
    "Parer\n",
    "Allan\n",
    "\n",
    "> python sample.py Chinese CHI\n",
    "Chan\n",
    "Hang\n",
    "Iun\n",
    "\n",
    "We are still hand-crafting a small RNN with a few linear layers\n",
    "but instead of predicting a category after reading in all letters of the \n",
    "name we input a category and output one letter at a time\n",
    "\n",
    "We will use the same data as the previous one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "we have a bunch of plain text files \n",
    "data/names/[Language].txt\n",
    "with a name per line \n",
    "\n",
    "we will split the lines into an array\n",
    "convert Unicode to ASCII\n",
    "and end up with a dictionary\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,;'-\"\n",
    "n_letters = len(all_letters) + 1 # Plus EOS marker\n",
    "\n",
    "def findFiles(path): return glob.glob(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "remove one extra letter is kept to \n",
    "signify the end of the text generation\n",
    "EOS marker so to speak\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(n_letters)\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, \n",
    "# thanks to http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# categories: 18 ['Spanish', 'Arabic', 'Greek', 'Polish', 'Czech', 'Chinese', 'Russian', 'Vietnamese', 'German', 'Scottish', 'Korean', 'English', 'Japanese', 'French', 'Italian', 'Dutch', 'Portuguese', 'Irish']\n",
      "O'Neal\n"
     ]
    }
   ],
   "source": [
    "# Read a file and split into lines\n",
    "\"\"\"\n",
    "\n",
    "read all the lines in a file \n",
    "and save each of all them seprately in a list called \"lines\"\n",
    "then send them each through the function unicodeToAscii to convert\n",
    "to plain ASCII\n",
    "this return a list with each item being a particular word\n",
    "\n",
    "\"\"\"        \n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "# Build the category_lines dictionary, a list of lines per category\n",
    "\"\"\"\n",
    "\n",
    "read each file separately \n",
    "category is the language name\n",
    "all_categories stores the names of all the languages\n",
    "\n",
    "lines is the list of all the words for that language \n",
    "as a list in ASCII format\n",
    "\n",
    "category_lines is a dictionary with the key \n",
    "being the language name and the data corresponding to the key\n",
    "being all the associated words with that language \n",
    "so category_lines dictionary structure is like this \n",
    "\n",
    "[english] : word1, word2, ....\n",
    "[french] : word1, word2, ....\n",
    "\n",
    "\"\"\"        \n",
    "category_lines = {}\n",
    "all_categories = []\n",
    "for filename in findFiles('data/names/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    all_categories.append(category)\n",
    "    lines = readLines(filename)\n",
    "    category_lines[category] = lines\n",
    "        \n",
    "n_categories = len(all_categories)\n",
    "        \n",
    "if n_categories == 0:\n",
    "    raise RuntimeError('Data not found. Make sure that you downloaded data '\n",
    "        'from https://download.pytorch.org/tutorial/data.zip and extract it to '\n",
    "        'the current directory.')\n",
    "        \n",
    "\n",
    "print('# categories:', n_categories, all_categories)\n",
    "print(unicodeToAscii(\"O'Néàl\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read it here https://pytorch.org/tutorials/intermediate/char_rnn_generation_tutorial.html#creating-the-network\n",
    "\n",
    "So here the input to the network is three things category tensor, input, hidden. Category is a one-hot tensor (dim no of categories) input is a one-hot tensor (dim no of n_letters) output must be a probability of the next letter  so output will be of dim of n_letters.\n",
    "\n",
    "[category, input, hidden] --> [combined]\n",
    "\n",
    "[combined] --> i2o --> [output]\n",
    "\n",
    "[combined] --> i2h --> [hidden] ==> input for next\n",
    "\n",
    "[output, hidden] --> [out_combined]\n",
    "\n",
    "[out_combined] --> o2o --> dropout --> softmax --> [output] ==> input for next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(n_categories + input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(n_categories + input_size + hidden_size, output_size)\n",
    "        self.o2o = nn.Linear(hidden_size + output_size, output_size)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, category, input, hidden):\n",
    "        input_combined = torch.cat((category, input, hidden), 1)\n",
    "        hidden = self.i2h(input_combined)\n",
    "        output = self.i2o(input_combined)\n",
    "        output_combined = torch.cat((hidden, output), 1)\n",
    "        output = self.o2o(output_combined)\n",
    "        output = self.dropout(output)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Preparing for Training\n",
    "\n",
    "a helper functions to get random pairs of(category, line)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import random\n",
    "\n",
    "# Random item from a list\n",
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "\n",
    "# Get a random category and random line from that category\n",
    "def randomTrainingPair():\n",
    "    \"\"\"\n",
    "    randomly choose a category\n",
    "    randomly choose a word from the category\n",
    "    \"\"\"\n",
    "    category = randomChoice(all_categories)\n",
    "    line = randomChoice(category_lines[category])\n",
    "    return category, line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "For each timestep ( that is for each letter in a training word ) the inputs of the network will be\n",
    "\n",
    "(category, current_letter, hidden_state)\n",
    "\n",
    "and the outputs will be \n",
    "\n",
    "(next_letter, next_hidden_state)\n",
    "\n",
    "Since we are predicting the next letter from the current letter for each \n",
    "timestep the letter pairs are groups of consecutive letters from the line \n",
    "e.g. \"ABCD <EOS>\"\n",
    "we create tuples like this\n",
    "(\"A\",\"B\"), (\"B\", \"C\"), (\"C\", \"D\"), (\"D\", \"EOS\")\n",
    "\n",
    "category input is 1 X n_categories \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# One-hot vector for category\n",
    "\"\"\"\n",
    "\n",
    "returns the category as a tensor of size 1 x n_categories\n",
    "\n",
    "\"\"\"\n",
    "def categoryTensor(category):\n",
    "    li = all_categories.index(category)\n",
    "    tensor = torch.zeros(1, n_categories)\n",
    "    tensor[0][li] = 1\n",
    "    return tensor\n",
    "\n",
    "# One-hot matrix of first to last letters (not including EOS) for input\n",
    "\"\"\"\n",
    "\n",
    "this is a matrix which consist of the tensor representation of all \n",
    "the letters in a particular word \n",
    "tensor is of shape no_of_letters_in_word X 1 X total_no_letters_in_vocab\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def inputTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li in range(len(line)):\n",
    "        letter = line[li]\n",
    "        tensor[li][0][all_letters.find(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "# LongTensor of second letter to end (EOS) for target\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "the same as the above function\n",
    "but does it for the target instead\n",
    "\n",
    "\"\"\"\n",
    "def targetTensor(line):\n",
    "    letter_indexes = [all_letters.find(line[li]) for li \n",
    "                      in range(1, len(line))]\n",
    "    letter_indexes.append(n_letters - 1) # EOS\n",
    "    return torch.LongTensor(letter_indexes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line tensor shape:  torch.Size([2, 1, 59])\n",
      "(tensor([[[1.]],\n",
      "\n",
      "        [[1.]]]), tensor([[[0]],\n",
      "\n",
      "        [[1]]]))\n",
      "target tensor shape: torch.Size([2]) tensor([ 1, 58])\n",
      "length of the line 2\n",
      "letter indices [1]\n",
      "[1, 58]\n"
     ]
    }
   ],
   "source": [
    "line = \"ab\"\n",
    "\n",
    "# this is for the input\n",
    "tensor = inputTensor(line)\n",
    "\n",
    "print('line tensor shape: ',tensor.shape)\n",
    "print(tensor.topk(1))\n",
    "\n",
    "# this is for the output\n",
    "tensor = targetTensor(line)\n",
    "\n",
    "print('target tensor shape:',tensor.shape, tensor)\n",
    "\n",
    "# so how is the target being generated ?\n",
    "print('length of the line',len(line))\n",
    "\n",
    "# collecting the indexes of the letters which serves as the target\n",
    "# look at that !! we are starting from range (1, ....)\n",
    "# so ignoring the first letter this is because that is not the target\n",
    "# for anything\n",
    "# so total no of letters now collected is len(line)-1\n",
    "letter_indexes = [all_letters.find(line[li]) for li \n",
    "                      in range(1, len(line))]\n",
    "print('letter indices',letter_indexes)\n",
    "\n",
    "# we also need to append the <EOS> marker \n",
    "# at the end\n",
    "letter_indexes.append(n_letters - 1) # EOS\n",
    "\n",
    "print(letter_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "For convenience during training we’ll make a randomTrainingExample \n",
    "function that fetches a random (category, line) pair and turns them\n",
    "into the required (category, input, target) tensors.\n",
    "\n",
    "\"\"\"\n",
    "# Make category, input, and target tensors from a random category, \n",
    "# line pair\n",
    "def randomTrainingExample():\n",
    "    category, line = randomTrainingPair()\n",
    "    category_tensor = categoryTensor(category)\n",
    "    input_line_tensor = inputTensor(line)\n",
    "    target_line_tensor = targetTensor(line)\n",
    "    return category_tensor, input_line_tensor, target_line_tensor\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "To keep track of how long training takes I am adding a timeSince\n",
    "(timestamp) function which returns a human readable string:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "In contrast to classification, where only the last output is used, we \n",
    "are making a prediction at every step, so we are calculating loss at \n",
    "every step.\n",
    "\n",
    "The magic of autograd allows you to simply sum these losses at each \n",
    "step and call backward at the end\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "learning_rate = 0.0005\n",
    "\n",
    "def train(category_tensor, input_line_tensor, target_line_tensor):\n",
    "    \n",
    "    target_line_tensor.unsqueeze_(-1)\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for i in range(input_line_tensor.size(0)):\n",
    "        output, hidden = rnn(category_tensor, input_line_tensor[i], hidden)\n",
    "        l = criterion(output, target_line_tensor[i])\n",
    "        loss += l\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(-learning_rate, p.grad.data)\n",
    "\n",
    "    return output, loss.item() / input_line_tensor.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 25s (5000 5%) 3.3606\n",
      "0m 51s (10000 10%) 2.5849\n",
      "1m 17s (15000 15%) 3.0229\n",
      "1m 43s (20000 20%) 3.2722\n",
      "2m 8s (25000 25%) 2.3661\n",
      "2m 32s (30000 30%) 2.0564\n",
      "2m 57s (35000 35%) 2.3906\n",
      "3m 21s (40000 40%) 1.5984\n",
      "3m 45s (45000 45%) 2.6805\n",
      "4m 12s (50000 50%) 2.7360\n",
      "4m 38s (55000 55%) 1.4615\n",
      "5m 4s (60000 60%) 2.5557\n",
      "5m 29s (65000 65%) 2.0077\n",
      "5m 54s (70000 70%) 2.7563\n",
      "6m 20s (75000 75%) 2.8336\n",
      "6m 47s (80000 80%) 2.3020\n",
      "7m 12s (85000 85%) 1.6084\n",
      "7m 37s (90000 90%) 2.3871\n",
      "8m 2s (95000 95%) 2.0772\n",
      "8m 29s (100000 100%) 2.5487\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Training is business as usual - call train a bunch of times and \n",
    "wait a few minutes, printing the current time and loss every \n",
    "print_every examples, and keeping store of an average loss per \n",
    "plot_every examples in all_losses for plotting later.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "rnn = RNN(n_letters, 128, n_letters)\n",
    "\n",
    "n_iters = 100000\n",
    "print_every = 5000\n",
    "plot_every = 500\n",
    "all_losses = []\n",
    "total_loss = 0 # Reset every plot_every iters\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "    \n",
    "    # get the input data and target data\n",
    "    category_tensor, input_line_tensor, target_line_tensor = randomTrainingExample()    \n",
    "    target_line_tensor.unsqueeze_(-1)\n",
    "    \n",
    "    # initialize the hidden units \n",
    "    # note that the hidden units are needed to be initialized \n",
    "    # for each example\n",
    "    # THIS IS VERY IMPORTANT\n",
    "    hidden = rnn.initHidden()    \n",
    "    \n",
    "    # remove the previous gradients associated with the model\n",
    "    rnn.zero_grad()\n",
    "    \n",
    "    # compute the loss\n",
    "    # the loss is per letter actually \n",
    "    loss = 0    \n",
    "    for i in range(input_line_tensor.size(0)):\n",
    "        output, hidden = rnn(category_tensor, input_line_tensor[i], hidden)\n",
    "        l = criterion(output, target_line_tensor[i])\n",
    "        loss += l\n",
    "        \n",
    "    # accumulate the gradients\n",
    "    loss.backward()\n",
    "    \n",
    "    # update the parameters of the network\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(-learning_rate, p.grad.data)\n",
    "    \n",
    "    loss = loss.item() / input_line_tensor.size(0)\n",
    "    \n",
    "    # compute the total loss \n",
    "    total_loss += loss\n",
    "\n",
    "    if iter % print_every == 0:\n",
    "        print('%s (%d %d%%) %.4f' % (timeSince(start), iter, iter / n_iters * 100, loss))\n",
    "\n",
    "    if iter % plot_every == 0:\n",
    "        all_losses.append(total_loss / plot_every)\n",
    "        total_loss = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the Losses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling the Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sample we give the network a letter and ask what is the next one\n",
    "feed that in as the next letter \n",
    "and repeat until the EOS token\n",
    "\n",
    "to do so these steps are needed to be done \n",
    "\n",
    "1. create tensors for input category, starting letter and empty \n",
    "hidden state\n",
    "\n",
    "2. create a string [output_name] with the starting letter \n",
    "\n",
    "3. up to a maximum output length \n",
    "\n",
    "  (a). feed the current letter to the network\n",
    "\n",
    "  (b). get the next letter from the highest output and the next hidden sate \n",
    "\n",
    "  (c). if the letter is <EOS> stop there \n",
    "\n",
    "  (d). if a regular letter comes up then add to the [output_name] and continue\n",
    "\n",
    "4. return the final name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 20\n",
    "\n",
    "# Sample from a category and starting letter\n",
    "\n",
    "def sample(category, start_letter='A'):\n",
    "    \n",
    "    with torch.no_grad():  # no need to track history in sampling\n",
    "        \n",
    "        category_tensor = categoryTensor(category)\n",
    "        \n",
    "        input = inputTensor(start_letter)\n",
    "        \n",
    "        hidden = rnn.initHidden()\n",
    "\n",
    "        output_name = start_letter\n",
    "\n",
    "        for i in range(max_length):\n",
    "            \n",
    "            output, hidden = rnn(category_tensor, input[0], hidden)\n",
    "            \n",
    "            topv, topi = output.topk(1)\n",
    "            \n",
    "            topi = topi[0][0]\n",
    "            \n",
    "            if topi == n_letters - 1:\n",
    "                # search for the <EOS> marker \n",
    "                break\n",
    "            else:\n",
    "                letter = all_letters[topi]\n",
    "                print(letter)\n",
    "                output_name += letter\n",
    "                print(output_name)\n",
    "            input = inputTensor(letter)\n",
    "\n",
    "        return output_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get multiple samples from one category and multiple starting letters\n",
    "\n",
    "def samples(category, start_letters='ABC'):\n",
    "    \n",
    "    for start_letter in start_letters:\n",
    "        \n",
    "        print(sample(category, start_letter))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "Ka\n",
      "l\n",
      "Kal\n",
      "l\n",
      "Kall\n",
      "o\n",
      "Kallo\n",
      "v\n",
      "Kallov\n",
      "Kallov\n"
     ]
    }
   ],
   "source": [
    "samples('Russian', 'K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e\n",
      "Ge\n",
      "r\n",
      "Ger\n",
      "r\n",
      "Gerr\n",
      "e\n",
      "Gerre\n",
      "Gerre\n",
      "r\n",
      "Er\n",
      "e\n",
      "Ere\n",
      "s\n",
      "Eres\n",
      "Eres\n",
      "o\n",
      "Ro\n",
      "u\n",
      "Rou\n",
      "r\n",
      "Rour\n",
      "e\n",
      "Roure\n",
      "Roure\n",
      "a\n",
      "Sa\n",
      "r\n",
      "Sar\n",
      "a\n",
      "Sara\n",
      "n\n",
      "Saran\n",
      "Saran\n",
      "a\n",
      "Pa\n",
      "r\n",
      "Par\n",
      "e\n",
      "Pare\n",
      "r\n",
      "Parer\n",
      "Parer\n",
      "r\n",
      "Ar\n",
      "a\n",
      "Ara\n",
      "n\n",
      "Aran\n",
      "e\n",
      "Arane\n",
      "Arane\n",
      "h\n",
      "Ch\n",
      "a\n",
      "Cha\n",
      "Cha\n",
      "u\n",
      "Hu\n",
      "n\n",
      "Hun\n",
      "Hun\n",
      "a\n",
      "Ia\n",
      "n\n",
      "Ian\n",
      "Ian\n",
      "l\n",
      "Al\n",
      "l\n",
      "All\n",
      "e\n",
      "Alle\n",
      "r\n",
      "Aller\n",
      "Aller\n",
      "a\n",
      "Ba\n",
      "r\n",
      "Bar\n",
      "s\n",
      "Bars\n",
      "Bars\n",
      "h\n",
      "Ch\n",
      "a\n",
      "Cha\n",
      "r\n",
      "Char\n",
      "s\n",
      "Chars\n",
      "Chars\n"
     ]
    }
   ],
   "source": [
    "samples('German', 'GER')\n",
    "\n",
    "samples('Spanish', 'SPA')\n",
    "\n",
    "samples('Chinese', 'CHI')\n",
    "\n",
    "samples('English', 'ABC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
